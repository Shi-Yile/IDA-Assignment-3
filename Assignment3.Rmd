---
title: "Incomplete Data Analysis - Assignment 3"
author: "Yile Shi (s2168022)"
date: "2022/3/31"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
Sys.setlocale("LC_ALL", "UK")
library(tidyverse)
library(mice)
library(JointAI)
library(corrplot)
library(devtools)
library(reshape2)
library(RColorBrewer)
library(ggplot2)
source_url("https://gist.githubusercontent.com/NErler/0d00375da460dd33839b98faeee2fdab/raw/c6f537ecf80eddcefd94992ec7926aa57d454536/propplot.R")
```

## Question 1

### (a) - Solution

Function `cc()` in `mice` package returns the complete cases in a dataset. Thus, we count the number of complete cases in dataset 'nhanes' and further compute the percentage of incomplete cases by $1 - \frac{\# complete\ cases}{\# all\ cases}$. 

As a result, we obtain the percentage of incomplete cases is $48\%$ ($12$ cases out of $25$).

```{r}
# the percentage of incomplete cases
1 - nrow(cc(nhanes)) / nrow(nhanes)
```

\newpage

### (b) - Solution

Recall that to estimate the variance of $\hat\theta^{MI}$, the multiple imputation of $\theta$, we calculate the following statistics:

\begin{enumerate}
  \item \textbf{between-imputation variance:} 
  $B = \frac{1}{M-1}\sum\limits_{i=1}^{M}\bigg(\hat\theta^{(i)} - \hat\theta^{MI}\bigg)^2$
  \item \textbf{within-imputation variance:}
  $\overline{U} = \frac{1}{M}\sum\limits_{i=1}^{M}\hat{U}^{(i)}$, where $\hat{U}^{(i)}$ is the estimated variance of $\hat\theta^{(i)}$
\end{enumerate}

Then we obtain the \textbf{total variance} $V^{MI} = \overline{U} + \bigg(1 + \frac{1}{M}\bigg)B$. Note that $M$ denotes the number of imputed datasets by `mice` ($M = 5$ by default).

According to the work by [Buuren et al. 2011](https://www.jstatsoft.org/article/view/v045i03), the proportion of total variance that is attributed to the missing values is 
$$\lambda = \frac{B + \frac{B}{M}}{V^{MI}}$$
We notice that `age` and `hyp` in our data are categorical variables hence we assign them as factors. Then we yield the following results with the standard MICE procedure - `mice()`, `with()` and `pool()`. Note that in step 2 (`with()`), we fit the normal linear regression of `bmi` over `age`, `hyp` and `chl`. 

As mentioned before, we look at the column `lambda` to get the proportion of variance due to missing data for each parameter (3 decimal places, seed = 1):

\begin{enumerate}
  \item $\lambda_{intercept} = 0.323$
  \item $\lambda_{age2} = 0.611$
  \item $\lambda_{age3} = 0.603$
  \item $\lambda_{hyp2} = 0.264$
  \item $\lambda_{chl} = 0.452$
\end{enumerate}

We observe that generally `age` factors have higher $\lambda$ values than others, where `age2`has the largest $\lambda$ of $0.611$. Note that the intercept includes `age1` and `hyp1` as baseline level, with the $\lambda$ value of $0.232$.  In conclusion, we consider `age` to be most affected by the non-response.

```{r}
# convert age and hyp to factors
nhanes$age <- as.factor(nhanes$age)
nhanes$hyp <- as.factor(nhanes$hyp)

# impute dataset with mice
imp.list <- mice(nhanes, printFlag = FALSE, seed = 1)

# linear model to predict bmi
bmi.fit <- with(imp.list, lm(bmi ~ age + hyp + chl))

# pool the results
bmi.pool <- pool(bmi.fit)
bmi.pool$pooled[, c(1, 3, 10)]
```

\newpage

### (c) - Solution

We repeat same analysis on $\lambda$ by using different random seeds from $2$ to $6$. The result are shown in the data frame below. 

We can observe that the conclusions in 1.(b) do not remain the same for different seeds. The values of $\lambda$ and the parameter most affected by the non-response vary dramatically.

For seed $3$, $4$ and $6$, `age` is considered to be most affected by the non-response, which is consistent with conclusions in 1.(b), using random seed $1$. Specifically, `age2` takes the largest $\lambda$ value $0.3075109$ for random seed $6$ and `age3` takes the largest $\lambda$ values $0.5147210$ and $0.5590423$ for seed $3$ and $4$ respectively.

On the other hand, `chl` takes the largest proportion of variance for seed $2$ and $5$, with values $0.5424351$ and $0.5294706$ of each. 

Recall that the larger amount of missing data, the larger the variability of values of $\lambda$ will be. Since nearly half ($48\%$) of cases in the dataset are incomplete, it is reasonable to have different conclusions every time we adjust the random seed.

```{r}
# create a data frame to store the results from different seeds
bmi.lambda <- data.frame(seed = 1, 
                         intercept = bmi.pool$pooled[1, 10],
                         age2 = bmi.pool$pooled[2, 10],
                         age3 = bmi.pool$pooled[3, 10],
                         hyp2 = bmi.pool$pooled[4, 10],
                         chl = bmi.pool$pooled[5, 10])

# repeat analysis with different seeds
for (i in seq(2, 6)){
  imp.list <- mice(nhanes, printFlag = FALSE, seed = i)
  bmi.fit <- with(imp.list, lm(bmi ~ age + hyp + chl))
  bmi.pool <- pool(bmi.fit)
  df <- data.frame(seed = i, 
                   intercept = bmi.pool$pooled[1, 10],
                   age2 = bmi.pool$pooled[2, 10],
                   age3 = bmi.pool$pooled[3, 10],
                   hyp2 = bmi.pool$pooled[4, 10],
                   chl = bmi.pool$pooled[5, 10])
  bmi.lambda <- rbind(bmi.lambda, df)
}
bmi.lambda
```

\newpage

### (d) - Solution

From 1.(c), we observe that the parameter most affected by the non-response varies as random seed changes. Thus, we expect that increasing the number of imputed datasets can lead to more consistent and stable results which has low dependence on the choice of random seed. 

We keep using same random seeds from $1$ to $6$, but change the number of imputed datasets, $M$, from $5$ to $100$. Again, we obtain a data frame with values of $\lambda$ for each parameter with different random seed.

Now we can find that `age` factors always take the largest proportion of variance due to missing cases (largest value of $\lambda$) for all $6$ seeds. To be more specific, `age2` is most affected by non-response for seed $4$ and $5$, with $\lambda$ values of $0.3623307$ and $0.3084504$ and in other cases `age3` has the largest $\lambda$ values. It appears that the conclusions become more consistent with $M = 100$, as we expected.

As far as I am concerned, I prefer the analyses with $M = 100$. 

Recall that the \textbf{total variance} of $\theta$ (`bmi` in this question) is calculated by
$$V^{MI} = \overline{U} + \bigg(1 + \frac{1}{M}\bigg)B$$
where $B = \frac{1}{M-1}\sum\limits_{i=1}^{M}\bigg(\hat\theta^{(i)} - \hat\theta^{MI}\bigg)^2$ and $\overline{U} = \frac{1}{M}\sum\limits_{i=1}^{M}\hat{U}^{(i)}$. 

Therefore, large value of $M$ can reduce the values of both $\overline{U}$ and $B$, and further the total variance, increasing the reliability of the estimates. In terms of high accuracy of predictions, larger number of imputed datasets is a better choice. 

However, time consumption and low statistical efficiency can be the problems of large value of $M$. When imputing large scaled dataset with a large number of missing values, large $M$ will relatively increase the running time. Moreover, the imputation procedure arrives at stable and statistically significant conclusions when $M$ reaches a certain value. Increasing $M$ beyond this value does not significantly influence the conclusions but consumes memory and time.

Overall, I still consider $M = 100$ as a better choice as the dataset in this question only have 25 observations and $100$ imputed datasets can be easily handled.

```{r}
# initialize the data frame
bmi.lambda.100 <- NULL
# repeat analysis with m = 100
for (i in seq(1, 6)){
  imp.list <- mice(nhanes, m = 100, printFlag = FALSE, seed = i) 
  bmi.fit <- with(imp.list, lm(bmi ~ age + hyp + chl))
  bmi.pool <- pool(bmi.fit)
  df <- data.frame(seed = i, 
                   intercept = bmi.pool$pooled[1, 10],
                   age2 = bmi.pool$pooled[2, 10],
                   age3 = bmi.pool$pooled[3, 10],
                   hyp2 = bmi.pool$pooled[4, 10],
                   chl = bmi.pool$pooled[5, 10])
  bmi.lambda.100 <- rbind(bmi.lambda.100, df)
}
bmi.lambda.100
```

\newpage

## Question 2

### Solution

As required, we apply stochastic regression imputation (SRI) and bootstrap sampling to generate the data in step $2$. To calculate the empirical coverage probability, according to \textbf{NOTE 1}, we define a counter to count the times when the ground truth value of $\beta_1$, i.e. $3$, is covered in its $95\%$ empirical confidence interval for each method and further obtain the probability with the corresponding frequency.

From the results below, we observe the empirical coverage probability of bootstrap imputation is larger than the probability of SRI ($0.95$ vs $0.88$). The reason for this is that stochastic regression imputation does not incorporate the variability of function weights, which means the uncertainty of imputed values is not considered, unlike bootstrap imputation. Thus, generally the $95\%$ confidence intervals obtained using SRI are more narrow and less likely to contain the ground truth value.

```{r}
# read dataset into R
load("dataex2.Rdata")

# initialize counters for empirical coverage probabilities of two methods
count.sri <- count.boot <- 0

# MICE standard procedure for each dataset
for (i in 1:100){
  
  # step 1 - mice()
  imp.sri <- mice(dataex2[, , i], m = 20, seed = 1, 
                  printFlag = FALSE, method = "norm.nob")
  imp.boot <- mice(dataex2[, , i], m = 20, seed = 1,
                   printFlag = FALSE, method = "norm.boot")
  
  # step 2 - with()
  fit.sri <- with(imp.sri, lm(Y ~ X))
  fit.boot <- with(imp.boot, lm(Y ~ X))
  
  # step 3 - pool()
  pool.sri <- summary(pool(fit.sri), conf.int = TRUE)
  pool.boot <- summary(pool(fit.boot), conf.int = TRUE)
  
  # if the ground truth, 3, is covered in the 95% CI of beta_1 ... 
  if (pool.sri$`2.5 %`[2] <= 3 & 3 <= pool.sri$`97.5 %`[2]){
    count.sri = count.sri + 1
  }
  if (pool.boot$`2.5 %`[2] <= 3 & 3 <= pool.boot$`97.5 %`[2]){
    count.boot = count.boot + 1
  }
}

# report the empirical coverage probability
data.frame(sri = count.sri / 100, bootstrap = count.boot / 100,
           row.names = "prob.")
```

\newpage

## Question 3

### Solution

We assume a general linear regression model $y = \pmb{x\beta} + \epsilon$ for the multiple imputation procedure. Here,
\begin{enumerate}
  \item $y= (y_1, y_2, \cdots, y_m)$:  response variable
  \item $\pmb{x} = (\pmb{1}, \pmb{x_1}, \pmb{x_2}, \cdots, \pmb{x_n})$: covariates (including intercept term)
  \item $\pmb{\beta} = (\beta_0, \beta_1, \beta_2, \cdots, \beta_n)$: coefficients
  \item $\epsilon \sim \mathcal{N}(0, \sigma^2)$: noise
\end{enumerate}

We start with strategy (i). 

Assume that step $1$ of the multiple imputation is performed and the number of imputed datasets is $M$. We fit the regression for each imputed dataset based on the pre-defined linear model and obtain the predicted values (point estimates) $\pmb{\hat{y}} = \big(\hat{y}^{(1)}, \hat{y}^{(2)}, \cdots, \hat{y}^{(M)}\big)$. We pool the predicted values according to Rubin's rule for point estimates:

$$
\begin{aligned}
  \tilde{y} &= \frac{1}{M}\sum\limits_{i = 1}^{M}\hat{y}^{(i)} \\
            &= \frac{1}{M}\sum\limits_{i = 1}^{M}\bigg(\beta_0^{(i)} + \sum\limits_{j = 1}^{n}\beta_j^{(i)} x_j \bigg) \\
            &= \tilde{\beta_0} + \frac{1}{M}\sum\limits_{i = 1}^{M}\sum\limits_{j = 1}^{n}\beta_j^{(i)} x_j \\
            &= \tilde{\beta_0} + \sum\limits_{j = 1}^{n}\bigg(x_j\ \cdot \frac{1}{M}\sum\limits_{i = 1}^{M}\beta_j^{(i)}\bigg) \\
            &= \tilde{\beta_0} + \sum\limits_{j = 1}^{n}\tilde{\beta_j}x_j
\end{aligned}
$$
where $\tilde{\beta_0} = \frac{1}{M}\sum\limits_{i = 1}^{M} \beta^{(i)}$ and $\tilde{\beta_j} = \frac{1}{M}\sum\limits_{i = 1}^{M} \beta_j^{(i)}, \ j = 1, \cdots, n$ are the pooled regression coefficients with intercept. 

Now we work on strategy (ii) with same notations used in (i). 

Before predicting, we pool the regression coefficients from each model, i.e. $\pmb{\beta^{(i)}} = \big(\beta_0^{(i)}, \beta_1^{(i)}, \cdots, \beta_n^{(i)}\big),\ i = 1, 2, \cdots, M$ in step $2$ using Rubin's rule for point estimates. In this way, we also obtain $\tilde{\beta_0} = \frac{1}{M}\sum\limits_{i = 1}^{M} \beta^{(i)}$ and $\tilde{\beta_j} = \frac{1}{M}\sum\limits_{i = 1}^{M} \beta_j^{(i)}, \ j = 1, \cdots, n$ and further the same predicting expression $\tilde{y} = \tilde{\beta_0} + \sum\limits_{j = 1}^{n}\tilde{\beta_j}x_j$ as we derived for strategy (i).

Therefore, the equations above prove that two strategies are mathematically equivalent and lead to same results and conclusions.

\newpage

## Question 4

### (a) - Solution

We need to prevent $x_2$ to be imputed and only impute $y$ and $x_1$ variables in step $1$. To this end, we pre-define the predictor matrix where the row for $x_2$ are all $0$s so that $x_2$ will not be imputed. Then we apply MICE on the dataset and consider the interaction term $x_1x_2$ in `with()` procedure. 

According to the `pool()` procedure, we obtain the estimates and $95\%$ confidence intervals of $\beta_1$, $\beta_2$ and $\beta_3$ as follows (3 decimal places):
\begin{enumerate}
  \item $\hat{\beta_1} = 1.411\ \ 95\%CI = (1.219, 1.603)$
  \item $\hat{\beta_2} = 1.966\ \ 95\%CI = (1.861, 2.071)$
  \item $\hat{\beta_3} = 0.755\ \ 95\%CI = (0.642, 0.868)$
\end{enumerate}

Comparing the results above with the ground truth values ($\beta_1 = 1, \beta_2 = 2, \beta_3 = 1$), we observe that only the $95\%$ confidence interval corresponding to $\beta_2$, the coefficient of complete column $x_2$, covers its true value, with a reasonable estimate. 

On the other hand, the estimates for imputed variables, $y$ and $x_1$, are relatively inaccurate and the corresponding $95\%$ confidence intervals fail to cover their true values. 

Based on these, we consider that the \emph{impute and then transform} method leads to biased estimates for imputed variables.

```{r}
# read dataset into R
load("dataex4.Rdata")

# create predictor matrix so that x_2 won't be imputed
pred.mat <- matrix(c(0, 1, 0, 1, 0, 0, 1, 1, 0), ncol = 3)
colnames(pred.mat) <- c("y", "x1", "x2")
rownames(pred.mat) <- c("y", "x1", "x2")

# MI only imputing y and x_1
imp.q4a <- mice(dataex4, m = 50, seed = 1, printFlag = FALSE,
                     predictorMatrix = pred.mat)  # mice() procedure
fit.q4a <- with(imp.q4a, lm(y ~ x1 + x2 + x1*x2)) # with() procedure
pool.q4a <- pool(fit.q4a)                         # pool() procedure

# report regression coefficients and 95% CIs
summary(pool.q4a, conf.int = TRUE)[, c("term", "estimate", "2.5 %", "97.5 %")]
```

\newpage

### (b) - Solution

Now we consider using \emph{passive imputation} to impute the missing values in the interaction variable $x_1x_2$. 

Since the original dataset does not contain the column for interaction variable, we calculate and add the interaction column into the dataset. Note that if $x_1 = NA$, the corresponding $x_1x_2 = NA$ too.

To apply \emph{passive imputation}, we modify the `method` argument for $x_1x_2$ so that its imputation method is the interaction of $x_1$ and $x_2$, i.e. $\sim I(x1*x2)$, in `mice()` procedure. Moreover, we make restrictions to the predictor matrix such that $y$ is not used to impute $x_1x_2$ and $x_1x_2$ is not considered when imputing $x_1$ and $x_2$. 

With everything ready, we implement multiple imputation on the dataset with pre-defined method and predictor matrix and obtain the estimates of each parameter with their 
$95\%$ confidence intervals.

\begin{enumerate}
  \item $\hat{\beta_1} = 1.193\ \ 95\%CI = (1.003, 1.382)$
  \item $\hat{\beta_2} = 1.996\ \ 95\%CI = (1.899, 2.094)$
  \item $\hat{\beta_3} = 0.874\ \ 95\%CI = (0.762, 0.987)$
\end{enumerate}

Comparing with \emph{impute and then transform} method, we obtain a more accurate estimate for $\beta_2$, with a narrower $95\%$ confidence interval including the true value, indicating higher accuracy of \emph{passive imputation}.

The estimates for $\beta_1$ and $\beta_3$ are also closer to the ground truth values, proving the improved estimation accuracy. However, the problem that the corresponding confidence intervals do not cover the true values of two parameters still arises.

Thus, we consider that the bias caused by the model is reduce by \emph{passive imputation} but still remains. 

```{r}
# calculate interaction variable and add to dataset
dataex4$x1x2 <- dataex4$x1 * dataex4$x2

# initial mice() to get the method
imp.q4b.0 <- mice(dataex4, m = 50, seed = 1, printFlag = FALSE)
# specify x1x2 is the interaction of x_1 and x_2
imp.q4b.0$method['x1x2'] <- "~I(x1*x2)"
# x_1 and x_2 should not be imputed by x1x2
imp.q4b.0$predictorMatrix[c("x1", "x2"), "x1x2"] <- 0 
# x1x2 should not be imputed by y
imp.q4b.0$predictorMatrix["x1x2", "y"] <- 0

# final MI 
imp.q4b <- mice(dataex4, m = 50, seed = 1, printFlag = FALSE,
                predictorMatrix = imp.q4b.0$predictorMatrix,
                method = imp.q4b.0$method)         # mice() procedure
fit.q4b <- with(imp.q4b, lm(y ~ x1 + x2 + x1x2))   # with() procedure
pool.q4b <- pool(fit.q4b)                          # pool() procedure

# report estimates and 95% CIs
summary(pool.q4b, conf.int = TRUE)[, c("term", "estimate", "2.5 %", "97.5 %")]
```

\newpage

### (c) - Solution

In this case, we consider the interaction variable $x_1x_2$ as \emph{just another variable}, meaning that we impute the missing values in $x_1x_2$ without depending on the missing values in $x_1$ variable. Thus, we directly construct the linear regression over 
$x_1$, $x_2$ and $x_1x_2$ in `with()` procedure, without any further steps.

As a result, we obtain the following estimates and $95\%$ confidence intervals of $\beta_1$, $\beta_2$ and $\beta_3$ (3 decimal places):
\begin{enumerate}
  \item $\hat{\beta_1} = 1.000\ \ 95\%CI = (0.841, 1.166)$
  \item $\hat{\beta_2} = 2.026\ \ 95\%CI = (1.940, 2.113)$
  \item $\hat{\beta_3} = 1.018\ \ 95\%CI = (0.930, 1.105)$
\end{enumerate}

We observe that the method treating the interaction $x_1x_2$ as \emph{just another variable} derives more accurate estimates for each parameter. Moreover, this method significantly improves the problem of model bias as the true value of each parameters are covered in its corresponding confidence interval. 

In terms of the data and model in our problem, we regard \emph{just another variable} method as the best performed imputation method among $3$ candidates. However, we need to point out that this method leads to the inconsistency of imputed values as we consider the interaction term independent with missing values in other variables when imputing.

```{r}
# consider x1x2 just as another variable
# MI
imp.q4c <- mice(dataex4, m = 50, seed = 1, printFlag = FALSE) # mice() procedure
fit.q4c <- with(imp.q4c, lm(y ~ x1 + x2 + x1x2))              # with() procedure
pool.q4c <- pool(fit.q4c)                                     # pool() procedure

# report the estimates and 95% CIs
summary(pool.q4c, conf.int = TRUE)[, c("term", "estimate", "2.5 %", "97.5 %")]
```

\newpage

### (d) - Solution

As mentioned in 4.(c), though \emph{just another variable} approach obtains unbiased estimates for each parameter in the linear regression, the inner dependence between the interaction term $x_1x_2$ and $x_1$ is violated. In other words, we impute the missing values of $x_1x_2$ independently from $x_1$, without considering the deterministic relationship between them.

\newpage

## Question 5

### Solution

***Exploratory Data Analysis***

We start our study with inspecting our data. Our dataset consists of $500$ cases with $12$ variables including $8$ continuous variables and $4$ factors:
\begin{itemize}
  \item \texttt{wgt:} weight in kg
  \item \texttt{gender:} male vs female
  \item \texttt{bili:} bilirubin concentration in mg/dL
  \item \texttt{age:} in years
  \item \texttt{chol:} total serum cholesterol in mg/dL,
  \item \texttt{HDL:} High-density lipoprotein cholesterol in mg/dL,
  \item \texttt{hgt:} height in metres,
  \item \texttt{educ:} educational status; $5$ ordered categories,
  \item \texttt{race:} $5$ unordered categories,
  \item \texttt{SBP:} systolic blood pressure in mmHg,
  \item \texttt{hypten:} hypertensive status; binary,
  \item \texttt{WC:} waist circumference in cm
\end{itemize}

According to the results from `summary()` function, variables `bili`, `chol`, `HDL`, `hgt`, `educ`, `SBP`, `hypten` and `WC` contains missing values. Note that some missing values in the dataset are presented by the string "NaN" rather than `NA`. Since we are going to use `mice` package for multiple imputation, which expects missing values coded as `NA`, we convert "NaN" to `NA` before any further steps, also for the consistency of notations. 

We investigate the missing data patterns intuitively using `md_pattern()` function from `JointAI` package. We can observe that the number of missing values for each variable is not large ($47$ for `bili` at most and $1$ for `educ` at least) and the number of fully observed cases is $411$ (out of $500$). (We'll revisit this fact later when determining the number of imputed datasets, $m$)

Moreover, we visualize the correlations between variables using `corrplot()` function from `corrplot` package. Recall that our model of interest is 
$$ wgt = \beta_0 + \beta_1gender + \beta_2age + \beta_3hgt + \beta_4WC + \epsilon, \quad \epsilon \sim N(0, \sigma^2)$$
According to the heat map below, we observe that there exists a strong positive correlation between the response variable `wgt` and `WC`. `gender` and `hgt` also have moderate correlations with `wgt`. However, the independent variable `age` shows a relatively low correlation with `wgt`, with a correlation efficient of $0.069$ ($3$ decimal places), which may lead to poor regression performance later. Another noteworthy fact is that `hgt` has a strong negative correlation with `gender`, which will be revisited later as it affects the imputation results of `hgt`.

Finally, we explore the distribution of each variable by visualizing it with `plot_all()` function from `JointAI` package. Continuous variables, except `hgt`, appear to have right-skewed distributions. Thus, using normal distribution for imputation method probably results in poor approximations and we keep using predictive mean matching (pmm) as default. Since we consider `hgt` can be well approximated by normal distribution, the imputation method of it will be modified to `norm`, the normal linear stochastic regression imputation regarding the uncertainty of data. 

```{r}
# read dataset into R
load("NHANES2.Rdata")

# data structure and summary
str(NHANES2)
summary(NHANES2)
```
```{r}
# convert NaN to NA
NHANES2 <- na_if(NHANES2, "NaN")

# transform factors to numeric
col.factor <- which(sapply(NHANES2, is.factor))
NHANES2.numeric <- NHANES2
NHANES2.numeric[, col.factor] <- sapply(NHANES2[, col.factor], as.numeric)
```

```{r, fig.height = 4}
# visualize missing pattern 
mdp <- md_pattern(NHANES2, pattern = TRUE, color = c("blue", "red"))
mdp$plot

# correlation plots
cor.NHANES2 <- cor(NHANES2.numeric, use = "complete.obs")
corrplot(cor.NHANES2, method = "color", title = "Correlation plot",
         tl.col = "black", diag = FALSE, type = "upper", mar = c(0, 0, 1, 0))

# visualize the distribution of observed values in each variable
par(mar = c(3, 3, 2, 1), mgp = c(2, 0.6, 0))
plot_all(NHANES2, breaks = 30, ncol = 4)
```
\newpage

***Multiple Imputation***

We begin multiple imputation with a dry/set-up run of `mice()` procedure. From the imputation summary, we observe the default imputation method for continuous variables is `pmm`. As mentioned before, we modify this imputation method for `hgt` to `norm`. Moreover, since `hgt` represents the individual's height in metres, we need to restrict the support the it. Here, we set a reasonable range of `hgt` to $[0.5, 2.8]$.

For factors, the methods are different depending on the number of classes in the factor. `logreg` is used for `hypten` as it is a binary variable, while `polr` is used for `educ` since this variable consists of multiple categories. 

Before any further imputation checks, we determine a proper number of imputed datasets, i.e. `m` argument in `mice()` function, based on both accuracy and statistical efficiency. To this end, we run complete multiple imputation procedures including `mice()`, `with()` and `pool()` with a set of candidates of $\texttt{m} \in \{5, 10, 15, 20, 25\}$ and repeat the procedures for $\texttt{seed} \in  \{1, 2, 3, 4, 5, 6\}$. We report the estimates for the regression coefficients as well as the running time using different seed for each candidate of `m`. 

As the data frames shown below, the variance of estimated regression coefficients gets smaller as `m` increases. However, this improvement becomes insignificant from $\texttt{m}=20$ to $\texttt{m}=25$. Meanwhile, we notice that the running time of each multiple imputation increases by around 10 seconds as the value of `m` increases by $5$ ($50$ seconds for $\texttt{m}=25$). 

Therefore, we prefer a multiple imputation on our dataset with $\texttt{m}=20$, which obtains both computationally efficiency and robust to random variation due to seed choice. Meanwhile, we set `maxit` argument to $20$ and keep random seed as $1$ for model reproducibility, without the loss of generality.

[\textbf{Note:} There is no doubt to use larger value of $m$ (e.g. $50$, $100$) to improve the model accuracy. However, in this case, the percentage of missing values in each variable is low ($9.4\%$ for `bili` at most) and over $80\%$ cases in the dataset are complete. Thus, we believe smaller $m$ can satisfy the requirements of both less variation and statistical efficiency.]

```{r}
# multiple imputation
# dry mice() procedure 
imp0 <- mice(data = NHANES2, maxit = 0)
imp0

# modify the imputation method of 'hgt'
imp0$method["hgt"] <- "norm"
# restrict the support of 'hgt'
imp0$post["hgt"] <- "imp[[j]][,i] <- squeeze(imp[[j]][,i], c(0.5, 2.8))"
```
```{r}
# MI for m = {5, 10, 15, 20, 25} with seed = {1, 2, 3, 4, 5, 6}
m.set <- c(5, 10, 15, 20, 25)
seed.set <- c(1, 2, 3, 4, 5 ,6)

for (i in m.set){
  est.df <- NULL
  for (j in seed.set){
    time.start <- Sys.time()
    imp.q5 <- mice(NHANES2, maxit = 20, m = i, seed = j,
                   method = imp0$method,
                   post = imp0$post, printFlag = FALSE)
    fit.q5 <- with(imp.q5, lm(wgt ~ gender + age + hgt + WC))
    pool.q5 <- pool(fit.q5)
    time.end <- Sys.time()
    df <- data.frame(seed = j,
                     genderfemale = pool.q5$pooled[2, "estimate"],
                     age = pool.q5$pooled[3, "estimate"],
                     hgt = pool.q5$pooled[4, "estimate"],
                     WC = pool.q5$pooled[5, "estimate"],
                     running.time = time.end - time.start)
    est.df <- rbind(est.df, df)
  }
  cat("regression estimates (m = ", i, "): \n", sep = "")
  print(est.df)
}
```
```{r}
# MI with m = 20 and seed = 1
imp.q5 <- mice(NHANES2, maxit = 20, m = 20, seed = 1, 
               method = imp0$method, 
               post = imp0$post, printFlag = FALSE)
fit.q5 <- with(imp.q5, lm(wgt ~ gender + age + hgt + WC))
pool.q5 <- pool(fit.q5)
```

(The imputation check continues in the next page.)

\newpage

***Imputation Check***

After applying a multiple imputation with proper arguments to our data, we conduct necessary checks. 

We first check if `mice()` found any problems during imputation with object `loggedEvents` and obtain the result `NULL`, indicating no problems detected. Furthermore, we check the Monte Carlo chains to ensure the convergence across all 12 variables. From the plots with $20$ MC chains for each variable, there exists no obvious pattern among well-mixing chains, suggesting good convergence for all variables. Note that the plot for the standard deviation of `educ` is blank as there is only $1$ missing values in this column.

Next, we inspect if the distribution of the imputed values agree with the distribution of the observed values, using `densityplot()` as well as `bwplot() ` functions from `mice` package for continuous variables and [`propplot()` function](https://gist.githubusercontent.com/NErler/0d00375da460dd33839b98faeee2fdab/raw/c6f537ecf80eddcefd94992ec7926aa57d454536/propplot.R) for categorical variables.

For continuous variables, except `hgt`, comparing with the distribution of their observed values ($\color{blue}{blue}$), their imputed values follow the similar distribution ($\color{red}{red}$). On the other hand, we can observe a clear left-shifted distribution of the imputed values of `hgt`. 

Recall that we observed high correlation between `hgt` and `gender` from the heat map. We guess this is the main reason for the shifted distribution of imputed `hgt`. To prove this, we next make a density plot of `hgt`, conditional on `gender`. As a result, we observe that `gender`  does strongly influences 
the imputed datasets. Specifically, values in `male` group has much more
narrow, concentrated distributions while the distribution in `female` group is wider.

For categorical variables, the distribution of imputed values of `educ` appears to be abnormal simply because we only imputed quite a few values each time, specifically $1$. The similar reason can also explain the discrepancies between the observed and imputed values for `hypten` (the percentage of missing values in this column is $4.2\%$). 

```{r, fig.height = 5}
# necessary checks for mice() procedure 
# problems check during mice() procedure
imp.q5$loggedEvents
# convergence check
plot(imp.q5, layout = c(2, 8))
```

```{r, fig.height = 3.5}
# distribution check
# case for continuous variables
bwplot(imp.q5)[c(2, 4, 5, 6, 7, 8)]
densityplot(imp.q5)
# distribution of hgt conditional on gender
densityplot(imp.q5, ~ hgt | gender)
```
```{r, warning = FALSE, fig.height = 3.5}
# case for categorised variables
propplot(imp.q5)
```

(The regression check and conclusions continue in the next page.)

\newpage

***Regression Check***

We have confirmed that our imputation step is successful. Before we reach the final conclusions, we also need to check if our model of interest fits well the \emph{completed} data. Moreover, we check if model performances across different subsets are consistent. Thus, we display the regression summaries for both subset $1$ and $20$ with plots.

According to the regression summaries, we observe that all independent variables, except `genderfemale` (`gender`), are significant with relatively low p-values. Moreover, $R^2$ around $85$ indicates good model explanation on response variable. Looking at the residual plots, we cannot observe obvious pattern of residuals, suggesting the linear assumption is met. The well-performed normal Q-Q plots shows the normality of error terms is satisfied. Thus, we consider our model to be well fitted.

The insignificance of `genderfemale` (`gender`) is also confirmed by implementing a multivariate Wald test. We fit another model without `gender` and compare the two models. The p-value of $0.1113$ indicates `gender` has no relevant contribution to the `wgt` model.

Recall that there is a strong linear relationship between `gender` and `hgt`, which influences the distribution of imputed values of `hgt`. Here, we may also consider it as a reason for the insignificant contribution of `gender`. Though the regression model appears to be good, we still need to solve this problem in future research to improve model performance. A easy and reasonable way is to drop `gender` from the model.

Since the results from different subsets are similar, we consider our models are consistent across subsets. Therefore, we finally pool the regression results and report the estimates of regression coefficients with their $95\%$ confidence intervals and p-values. The regression expression is:
$$ wgt = -100.960 - 1.324 \times genderfemale - 0.156 \times age + 52.498 \times hgt + 1.025 \times WC $$
As expected, the coefficient of `gender` is insignificant. Moreover, we report the pooled adjusted $R^2$, where the value of around $0.85$ indicates good model explanation.

```{r}
# with() procedure (regression) check
summary(fit.q5$analyses[[1]])
par(mfrow = c(2, 2))
plot(fit.q5$analyses[[1]])

summary(fit.q5$analyses[[20]])
par(mfrow = c(2, 2))
plot(fit.q5$analyses[[20]])
```
```{r}
# Wald test
fit.q5.nogender <- with(imp.q5, lm(wgt ~ age + hgt + WC))
D1(fit.q5, fit.q5.nogender)
```

```{r}
# pool() procedure check
pool.q5
summary.q5 <- summary(pool.q5, conf.int = TRUE)
summary.q5
```

```{r}
# report regression coefficients and CIs with p-values
df <- data.frame(estimate = summary.q5[, 2],
                 lower = summary.q5[, 7],
                 upper = summary.q5[, 8],
                 p.value = summary.q5[, 6],
                 row.names = c("$\\beta_0$", "$\\beta_1$",
                               "$\\beta_2$", "$\\beta_3$", "$\\beta_4$"))
colnames(df) <- c("estimate", "2.5% quantile", "97.5% quantile", "p-value")
knitr::kable(df, escape = FALSE, digits = 3, 
             caption = "Regression coefficients, 95% CIs and p-values")
```

```{r}
# pooled R^2
pool.r.squared(pool.q5, adjusted = TRUE)
```






